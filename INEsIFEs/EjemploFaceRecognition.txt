import face_recognition
import cv2
import numpy as np
import glob
import os
import logging
import json

# IMAGES_PATH = '/home/erick/PycharmProjects/Base/INEsIFEs/FotosApp/INEs'  # put your reference images in here
MAX_DISTANCE = 0.6  # increase to make recognition less strict, decrease to make more strict


def get_face_embeddings_from_image(image, convert_to_rgb=False):
    """
    Take a raw image and run both the face detection and face embedding model on it
    """
    # Convert from BGR to RGB if needed
    if convert_to_rgb:
        image = image[:, :, ::-1]

    # run the face detection model to find face locations
    face_locations = face_recognition.face_locations(image)

    # run the embedding model to get face embeddings for the supplied locations
    face_encodings = face_recognition.face_encodings(image, face_locations)

    return face_locations, face_encodings


def setup_database(images_path):
    """
    Load reference images and create a database of their face encodings
    """
    database = {}

    for filename in glob.glob(os.path.join(images_path, '*.jpg')):
        # load image
        image_rgb = face_recognition.load_image_file(filename)

        # use the name in the filename as the identity key
        identity = os.path.splitext(os.path.basename(filename))[0]

        # get the face encoding and link it to the identity
        locations, encodings = get_face_embeddings_from_image(image_rgb)
        database[identity] = encodings[0]

        with open('faces_db.txt', 'w') as db_file:
            db_file.write(json.dumps(database))

    return database


'''database = setup_database()

frame = cv2.imread('/home/erick/PycharmProjects/Base/INEsIFEs/FotosApp/Sonrisas/photo18.jpg')

# run detection and embedding models
face_locations, face_encodings = get_face_embeddings_from_image(frame, convert_to_rgb=True)

# the face_recognition library uses keys and values of your database separately
known_face_encodings = list(database.values())
known_face_names = list(database.keys())

# Loop through each face in this frame of video and see if there's a match
for location, face_encoding in zip(face_locations, face_encodings):

    # get the distances from this encoding to those of all reference images
    distances = face_recognition.face_distance(known_face_encodings, face_encoding)

    # select the closest match (smallest distance) if it's below the threshold value
    if np.any(distances <= MAX_DISTANCE):
        best_match_idx = np.argmin(distances)
        name = known_face_names[best_match_idx]
    else:
        name = None

    # show recognition info on the image
    print('This person is: ', name)'''
 
